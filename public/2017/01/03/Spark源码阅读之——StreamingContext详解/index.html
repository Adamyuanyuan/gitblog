<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Spark源码阅读之——StreamingContext详解 | Adam Home</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Spark源码阅读之——StreamingContext详解</h1><a id="logo" href="/.">Adam Home</a><p class="description">快意回首，拂心莫停</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于我</i></a><a href="/timeline/"><i class="fa fa-line-chart"> 历史</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Spark源码阅读之——StreamingContext详解</h1><div class="post-meta">Jan 3, 2017<span> | </span><span class="category"><a href="/categories/spark/">spark</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#引言"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#StreamingContext的创建"><span class="toc-number">1.1.</span> <span class="toc-text">StreamingContext的创建</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#StreamingContext的初始化"><span class="toc-number">1.2.</span> <span class="toc-text">StreamingContext的初始化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#StreamingContext的控制"><span class="toc-number">1.3.</span> <span class="toc-text">StreamingContext的控制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#引用"><span class="toc-number">1.4.</span> <span class="toc-text">引用</span></a></li></ol></li></ol></div></div><div class="post-content"><p><a href="https://github.com/lw-lin/CoolplaySpark/tree/master/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97" target="_blank" rel="external">Spark Streaming 源码解析系列</a>很好地解析了Spark Streaming框架的源码，遗留了一点关于StreamingContext的解析，我基于自己的理解，简要阐述如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">本系列内容适用范围：</div><div class="line">* 2016.12.28 update, Spark 2.1 全系列 √ (2.1.0)</div><div class="line">* 2016.11.14 update, Spark 2.0 全系列 √ (2.0.0, 2.0.1, 2.0.2)</div><div class="line">* 2016.11.07 update, Spark 1.6 全系列 √ (1.6.0, 1.6.1, 1.6.2, 1.6.3)</div></pre></td></tr></table></figure>
<p>阅读本文前，请一定先阅读 <a href="0.1 Spark Streaming 实现思路与模块概述.md">Spark Streaming 实现思路与模块概述</a> 一文，其中概述了 Spark Streaming 的 4 大模块的基本作用，有了全局概念后再看本文对 <code>StreamingContext</code> 细节的解释。</p>
<h2 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h2><p><img src="040.png" alt="image"></p>
<p>如各个模块的架构图所示，<code>StreamingContext</code> 是 Spark Streaming 提供给用户 code 的、与前述 4 个模块交互的一个简单和统一的入口，是Spark Streaming程序与Spark Core的连接器，下面我们用这段11行的完整 <a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html#a-quick-example" target="_blank" rel="external">quick example</a>，来说明用户 code 是怎么通过 <code>StreamingContext</code> 与前面几个模块进行交互的：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">import</span> org.apache.spark._</div><div class="line"><span class="keyword">import</span> org.apache.spark.streaming._</div><div class="line"></div><div class="line"><span class="comment">// 首先配置一下本 quick example 将跑在本机，app name 是 NetworkWordCount</span></div><div class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setMaster(<span class="string">"local[2]"</span>).setAppName(<span class="string">"NetworkWordCount"</span>)</div><div class="line"><span class="comment">// batchDuration 设置为 1 秒，然后创建一个 streaming 入口</span></div><div class="line"><span class="keyword">val</span> ssc = <span class="keyword">new</span> <span class="type">StreamingContext</span>(conf, <span class="type">Seconds</span>(<span class="number">1</span>))</div><div class="line"></div><div class="line"><span class="comment">// ssc.socketTextStream() 将创建一个 SocketInputDStream；这个 InputDStream 的 SocketReceiver 将监听本机 9999 端口</span></div><div class="line"><span class="keyword">val</span> lines = ssc.socketTextStream(<span class="string">"localhost"</span>, <span class="number">9999</span>)</div><div class="line"></div><div class="line"><span class="keyword">val</span> words = lines.flatMap(_.split(<span class="string">" "</span>))      <span class="comment">// DStream transformation</span></div><div class="line"><span class="keyword">val</span> pairs = words.map(word =&gt; (word, <span class="number">1</span>))     <span class="comment">// DStream transformation</span></div><div class="line"><span class="keyword">val</span> wordCounts = pairs.reduceByKey(_ + _)    <span class="comment">// DStream transformation</span></div><div class="line">wordCounts.print()                           <span class="comment">// DStream output</span></div><div class="line"><span class="comment">// 上面 4 行利用 DStream transformation 构造出了 lines -&gt; words -&gt; pairs -&gt; wordCounts -&gt; .print() 这样一个 DStreamGraph</span></div><div class="line"><span class="comment">// 但注意，到目前是定义好了产生数据的 SocketReceiver，以及一个 DStreamGraph，这些都是静态的</span></div><div class="line"></div><div class="line"><span class="comment">// 下面这行 start() 将在幕后启动 JobScheduler, 进而启动 JobGenerator 和 ReceiverTracker</span></div><div class="line"><span class="comment">// ssc.start()</span></div><div class="line"><span class="comment">//    -&gt; JobScheduler.start()</span></div><div class="line"><span class="comment">//        -&gt; JobGenerator.start();    开始不断生成一个一个 batch</span></div><div class="line"><span class="comment">//        -&gt; ReceiverTracker.start(); 开始往 executor 上分布 ReceiverSupervisor 了，也会进一步创建和启动 Receiver</span></div><div class="line">ssc.start()</div><div class="line"></div><div class="line"><span class="comment">// 然后用户 code 主线程就 block 在下面这行代码了</span></div><div class="line"><span class="comment">// block 的后果就是，后台的 JobScheduler 线程周而复始的产生一个一个 batch 而不停息</span></div><div class="line"><span class="comment">// 也就是在这里，我们前面静态定义的 DStreamGraph 的 print()，才一次一次被在 RDD 实例上调用，一次一次打印出当前 batch 的结果</span></div><div class="line">ssc.awaitTermination()</div></pre></td></tr></table></figure>
<p>从上述样例程序可知，程序的前两行创建了一个新的 <code>StreamingContext</code>，第三行通过 <code>ssc.socketTextStream</code>通过ssc暴露的方法创建了一个<code>ReceiverInputDStream</code>，接着基于DStream的各种方法对数据进行了操作，最后通过 <code>ssc.start</code> 方法启动了Spark Streaming 程序，最后一句<code>ssc.awaitTermination()</code>将用户 code 主线程 block 住，由后台的 JobScheduler 线程周而复始的产生一个一个 batch 而不停息地处理，除非发生异常。</p>
<p>我们可以发现，StreamingContext主要包含以下内容：</p>
<ul>
<li>StreamingContext的创建(构造函数)</li>
<li>StreamingContext的初始化(成员)</li>
<li>StreamingContext的状态控制(函数)</li>
</ul>
<h3 id="StreamingContext的创建"><a href="#StreamingContext的创建" class="headerlink" title="StreamingContext的创建"></a>StreamingContext的创建</h3><p>首先我们来看<code>StreamingContext</code>的构造函数，主要由三个参数，分别是：</p>
<ul>
<li>SparkContext：SparkStreaming的最终处理是交给SparkContext的；</li>
<li>Checkpoint：检查点，用于错误恢复；</li>
<li>Duration：设定Streaming每个批次的积累时间。</li>
</ul>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">StreamingContext</span> <span class="title">private</span>[streaming] (<span class="params"></span></span></div><div class="line">    _sc: <span class="type">SparkContext</span>,</div><div class="line">    _cp: <span class="type">Checkpoint</span>,</div><div class="line">    _batchDur: <span class="type">Duration</span></div><div class="line">  ) <span class="keyword">extends</span> <span class="title">Logging</span> &#123;</div></pre></td></tr></table></figure>
<p><code>StreamingContext</code> 有以下几种不同的创建方式：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment">// 1. 通过已经存在的SparkContext创建.</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(sparkContext: <span class="type">SparkContext</span>, batchDuration: <span class="type">Duration</span>) = &#123;</div><div class="line">  <span class="keyword">this</span>(sparkContext, <span class="literal">null</span>, batchDuration)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// 2. 通过SparkConf中的配置信息来来创建.</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(conf: <span class="type">SparkConf</span>, batchDuration: <span class="type">Duration</span>) = &#123;</div><div class="line">  <span class="keyword">this</span>(<span class="type">StreamingContext</span>.createNewSparkContext(conf), <span class="literal">null</span>, batchDuration)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// 3. 通过一些必要参数来创建</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(</div><div class="line">    master: <span class="type">String</span>,</div><div class="line">    appName: <span class="type">String</span>,</div><div class="line">    batchDuration: <span class="type">Duration</span>,</div><div class="line">    sparkHome: <span class="type">String</span> = <span class="literal">null</span>,</div><div class="line">    jars: <span class="type">Seq</span>[<span class="type">String</span>] = <span class="type">Nil</span>,</div><div class="line">    environment: <span class="type">Map</span>[<span class="type">String</span>, <span class="type">String</span>] = <span class="type">Map</span>()) = &#123;</div><div class="line">  <span class="keyword">this</span>(<span class="type">StreamingContext</span>.createNewSparkContext(master, appName, sparkHome, jars, environment),</div><div class="line">       <span class="literal">null</span>, batchDuration)</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// 4. 从checkpoint文件中读取来重新创建</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(path: <span class="type">String</span>, hadoopConf: <span class="type">Configuration</span>) =</div><div class="line">  <span class="keyword">this</span>(<span class="literal">null</span>, <span class="type">CheckpointReader</span>.read(path, <span class="keyword">new</span> <span class="type">SparkConf</span>(), hadoopConf).orNull, <span class="literal">null</span>)</div><div class="line"></div><div class="line"><span class="comment">// ...</span></div><div class="line"><span class="comment">// 5. 已经存在的SparkContext，通过读取checkpoint文件重新创建</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">this</span></span>(path: <span class="type">String</span>, sparkContext: <span class="type">SparkContext</span>) = &#123;</div><div class="line">  <span class="keyword">this</span>(</div><div class="line">    sparkContext,</div><div class="line">    <span class="type">CheckpointReader</span>.read(path, sparkContext.conf, sparkContext.hadoopConfiguration).orNull,</div><div class="line">    <span class="literal">null</span>)</div><div class="line">&#125;</div><div class="line"><span class="comment">// ...</span></div><div class="line"><span class="comment">// 6. 值得一提的是，StreamingContext对象提供了一个构造方法，如果存在Checkpoint就通过Checkpoint创建，否则新建一个StreamingContext</span></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">getOrCreate</span></span>(</div><div class="line">    checkpointPath: <span class="type">String</span>,</div><div class="line">    creatingFunc: () =&gt; <span class="type">StreamingContext</span>,</div><div class="line">    hadoopConf: <span class="type">Configuration</span> = <span class="type">SparkHadoopUtil</span>.get.conf,</div><div class="line">    createOnError: <span class="type">Boolean</span> = <span class="literal">false</span></div><div class="line">  ): <span class="type">StreamingContext</span> = &#123;</div><div class="line">  <span class="keyword">val</span> checkpointOption = <span class="type">CheckpointReader</span>.read(</div><div class="line">    checkpointPath, <span class="keyword">new</span> <span class="type">SparkConf</span>(), hadoopConf, createOnError)</div><div class="line">  checkpointOption.map(<span class="keyword">new</span> <span class="type">StreamingContext</span>(<span class="literal">null</span>, _, <span class="literal">null</span>)).getOrElse(creatingFunc())</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>整理上述的文件创建过程，可以看出，StreamingContext的创建是一定要包含SparkContext的，同理也可以推出，Spark Streaming最终实际是交给SparkContext来处理的，Spark Streaming更像是Spark Core的一个应用程序。<br><code>StreamingContext</code>的创建主要分为两类：</p>
<ul>
<li>1: 通过SparkContext建立新的StreamingContext，需要指定<code>batchDuration</code>时间；</li>
<li>2: 从checkpoint文件中读取的Checkpoint对象中创建StreamingContext，用于异常情况下的恢复，<code>batchDuration</code>在Checkpoint中已经保存，所以可以不用显示指定。</li>
</ul>
<p>所以说，要构建StreamingContext，就必须要以上两者至少选一，下面的代码也说明了这点：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">require(_sc != <span class="literal">null</span> || _cp != <span class="literal">null</span>,</div><div class="line">  <span class="string">"Spark Streaming cannot be initialized with both SparkContext and checkpoint as null"</span>)</div></pre></td></tr></table></figure>
<p>注意：由于SparkStreaming至少需要一个线程来接收数据，所以local与local[1]模式下是不可以启动的。</p>
<h3 id="StreamingContext的初始化"><a href="#StreamingContext的初始化" class="headerlink" title="StreamingContext的初始化"></a>StreamingContext的初始化</h3><p>StreamingContext在创建后会进行一些初始化（静态定义）的工作，定义一些静态的数据结构，由图可知，StreamingContext主要持有 DStreamGraph 与 JobScheduler 的对象：</p>
<p>如下是graph的初始化定义代码，如果之前存在 Checkpoint ，则graph从 Checkpoint 得到，否则创建一个新的graph<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[streaming] <span class="keyword">val</span> graph: <span class="type">DStreamGraph</span> = &#123;</div><div class="line">  <span class="keyword">if</span> (isCheckpointPresent) &#123;</div><div class="line">    _cp.graph.setContext(<span class="keyword">this</span>)</div><div class="line">    <span class="comment">// 遍历从Checkpoint数据中恢复出RDD</span></div><div class="line">    _cp.graph.restoreCheckpointData()</div><div class="line">    _cp.graph</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    require(_batchDur != <span class="literal">null</span>, <span class="string">"Batch duration for StreamingContext cannot be null"</span>)</div><div class="line">    <span class="keyword">val</span> newGraph = <span class="keyword">new</span> <span class="type">DStreamGraph</span>()</div><div class="line">    newGraph.setBatchDuration(_batchDur)</div><div class="line">    newGraph</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<p>如下是初始化jobScheduler的代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span>[streaming] <span class="keyword">val</span> scheduler = <span class="keyword">new</span> <span class="type">JobScheduler</span>(<span class="keyword">this</span>)</div></pre></td></tr></table></figure></p>
<p>除了上述两个主要成员，StreamingContext还包含以下成员：</p>
<ul>
<li>ContextWaiter：用于等待任务执行结束；</li>
<li>StreamingJobProgressListener：用于监听StreamingJob，用以更新StreamingTab的显示；</li>
<li>StreamingTab：用于生成SparkUI中Streaming那一页标签；</li>
<li>StreamingSource： 流式计算的测量数据源metrics。</li>
</ul>
<p>除了定义上述成员，StreamingContext还进行了Checkpoint,创建了Checkpoint目录：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">conf.getOption(<span class="string">"spark.streaming.checkpoint.directory"</span>).foreach(checkpoint)</div></pre></td></tr></table></figure>
<p>checkpoint方法如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 创建Checkpoint目录</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">checkpoint</span></span>(directory: <span class="type">String</span>) &#123;</div><div class="line">  <span class="keyword">if</span> (directory != <span class="literal">null</span>) &#123;</div><div class="line">    <span class="keyword">val</span> path = <span class="keyword">new</span> <span class="type">Path</span>(directory)</div><div class="line">    <span class="keyword">val</span> fs = path.getFileSystem(sparkContext.hadoopConfiguration)</div><div class="line">    fs.mkdirs(path)</div><div class="line">    <span class="keyword">val</span> fullPath = fs.getFileStatus(path).getPath().toString</div><div class="line">    sc.setCheckpointDir(fullPath)</div><div class="line">    checkpointDir = fullPath</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    checkpointDir = <span class="literal">null</span></div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="StreamingContext的控制"><a href="#StreamingContext的控制" class="headerlink" title="StreamingContext的控制"></a>StreamingContext的控制</h3><p>StreamingContext作为控制面板，给用户提供了许多控制方法，就像控制面板上的按钮，让我们来开发spark Streaming程序，主要有以下方法：</p>
<ul>
<li>sparkContext： 获得ssc所属的SparkContext</li>
<li>remember(duration: Duration)：通过设置 <code>graph.remember(duration)</code> 来设置<code>rememberDuration</code></li>
</ul>
<p>简单解释一下<code>rememberDuration</code>，Spark Streaming 会在每个Batch任务结束时进行一次清理动作<code>clearMetadata</code>，每个DStream 都会被扫描，先清理输出Dstream，接着清理输入DStream，清理的时候，根据<code>rememberDuration</code>来计算出oldRDD然后清理。<code>rememberDuration</code> 有默认值，大体是<code>slideDuration</code>，也就是DStream生成RDD的时间间隔，如果设置了checkpointDuration 则是2*checkpointDuration，手动指定的值要大于默认值才会生效。</p>
<p>接下来是定义一些定义输入流的方法，主要有：</p>
<ul>
<li>receiverStream<a href="receiver: Receiver[T]" target="_blank" rel="external">T: ClassTag</a>：创建一个用户自定义的Receiver；</li>
<li>socketTextStream：创建TCP socketReceiver，默认是utf-8的文本格式，以’\n’分隔；</li>
<li>socketStream：创建TCP socketReceiver，用户提供自己的转化函数；</li>
<li>rawSocketStream：创建SocketReceiver，相比上着，没有中间的解码转化所以比较高效；</li>
<li>fileStream：创建监控HDFS目录的InputDStream，通过检测文件的修改时间来判断是否是新文件；</li>
<li>binaryRecordsStream：创建二进制文件的监听InputDStream，使用了fileStream方法；</li>
<li>queueStream：创建一个RDD队列流，底层调用了UnionRDD的方法将这些RDD转化为一个RDD，开启oneAtATime参数则每个RDD只取一个值，可以用于调试和测试；</li>
</ul>
<p>在InputDStream的构造过程中，会将此输入流InputDStream添加到DStreamGraph的inputStreams数据结构中，<br><figure class="highlight scala"><figcaption><span>InputDStream.scala</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">ssc.graph.addInputStream(<span class="keyword">this</span>)</div></pre></td></tr></table></figure></p>
<p>还定义了一些DStream的其它方法：</p>
<ul>
<li>union： 多个DStreams合成一个DStream，底层调用了ssc.sc.union(rdds)；</li>
<li>transform： 根据自定义的transformFunc生成新的DStream；</li>
<li>addStreamingListener： 在listenerBus上增加一个StreamingListener对象，供JobScheduler的StreamingListenerBus对象监听输入流的ReceiverRateController对象；</li>
</ul>
<p>还定义了一些控制启动与关闭的方法：</p>
<ul>
<li>start：启动StreamingContext。</li>
</ul>
<p>StreamingContext的start方法启动过程中，会判断StreamingContext的状态，它有三个状态INITIALIZED、ACTIVE、STOP。只有状态为INITAILIZED才允许启动，主要有以下步骤：</p>
<ol>
<li>验证graph是否有效；</li>
<li>设置Checkpoint；</li>
<li>使用新的线程异步启动 JobScheduler ，启动后将状态由初始化状态INITIALIZED改为ACTIVE状态，JobScheduler的启动请见<a href="https://github.com/lw-lin/CoolplaySpark/blob/master/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97/2.2%20JobGenerator%20%E8%AF%A6%E8%A7%A3.md" target="_blank" rel="external">JobGenerator 详解</a>；</li>
<li>同时添加Streaming的shutdownHookRef，用于程序的异常终止，StreamingContext的shutdownHook优先级比SparkContext的值大1；</li>
<li>往metricsSystem中注册streamingSource测量数据源；</li>
<li>添加生成SparkUI中Streaming相关标签</li>
</ol>
<ul>
<li>awaitTermination：等待Streaming程序的停止；</li>
<li>stop：停止SparkStreaming程序，其中可以传入参数以表示是否同时停止相关的SparkContext，默认为true(这个参数在文件名流转化为数据流的时候应该设置为false，通过spark.streaming.stopSparkContextByDefault来设置);还有一个参数是是否优雅地停止(等待其它已经接收到的数据处理完毕再停止)；</li>
</ul>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p><a href="http://lqding.blog.51cto.com/9123978/1771017" target="_blank" rel="external">http://lqding.blog.51cto.com/9123978/1771017</a><br><a href="https://github.com/lw-lin/CoolplaySpark/tree/master/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97" target="_blank" rel="external">https://github.com/lw-lin/CoolplaySpark/tree/master/Spark%20Streaming%20%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E7%B3%BB%E5%88%97</a><br><a href="http://lqding.blog.51cto.com/9123978/1773912" target="_blank" rel="external">http://lqding.blog.51cto.com/9123978/1773912</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://flume.cn/2017/01/03/Spark源码阅读之——StreamingContext详解/" data-id="cjgd2byey0020egguvztnywkp" class="article-share-link">分享</a><div class="tags"><a href="/tags/spark-streaming/">spark streaming</a></div><div class="post-nav"><a href="/2017/01/09/大数据团队scala代码规范/" class="pre">大数据团队scala代码规范</a><a href="/2016/12/19/spark中读取hdfs文件简记/" class="next">spark中读取hdfs文件简记</a></div><div id="uyan_frame"></div><script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2139407"></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/eagle/">eagle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/scala/">scala</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark开发/">spark开发</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spring-cloud/">spring cloud</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/单车岁月/">单车岁月</a><span class="category-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/大数据开发/" style="font-size: 15px;">大数据开发</a> <a href="/tags/scala/" style="font-size: 15px;">scala</a> <a href="/tags/hue/" style="font-size: 15px;">hue</a> <a href="/tags/kerberos/" style="font-size: 15px;">kerberos</a> <a href="/tags/livy/" style="font-size: 15px;">livy</a> <a href="/tags/hbase/" style="font-size: 15px;">hbase</a> <a href="/tags/yarn/" style="font-size: 15px;">yarn</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/flume/" style="font-size: 15px;">flume</a> <a href="/tags/spark-streaming/" style="font-size: 15px;">spark streaming</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/持续更新/" style="font-size: 15px;">持续更新</a> <a href="/tags/spark开发/" style="font-size: 15px;">spark开发</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/散文/" style="font-size: 15px;">散文</a> <a href="/tags/eagle/" style="font-size: 15px;">eagle</a> <a href="/tags/架构/" style="font-size: 15px;">架构</a> <a href="/tags/spring-cloud/" style="font-size: 15px;">spring cloud</a> <a href="/tags/微服务/" style="font-size: 15px;">微服务</a> <a href="/tags/es/" style="font-size: 15px;">es</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/01/08/spark2-2新版本编译打包/">spark2.2新版本编译打包</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/31/使用Ansable安装管理Spark客户端/">使用Ansable安装管理Spark客户端</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/17/spark往ES中写入数据的方法/">spark往ES中写入数据的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/17/spark指定java版本向yarn提交程序/">spark在yarn中运行jdk8</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/29/返回区域实时人数的思路与总结/">返回区域实时人数的思路与总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/28/位置服务开发上线总结/">位置服务开发上线总结————实时数据推送</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/22/spark奇技淫巧总结之flatMap/">spark奇技淫巧总结之强大的flatMap</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/22/OpenAPI微服务接入规范/">OpenAPI微服务接入规范</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/29/OpenApi之我浅薄见解/">OpenApi之我浅薄见解</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/24/阿里巴巴Java开发手册学习笔记2/">阿里巴巴Java开发手册学习笔记（下）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://issues.apache.org/jira/secure/Dashboard.jspa" title="有问题上JIRA" target="_blank">有问题上JIRA</a><ul></ul><a href="https://github.com/lw-lin/CoolplaySpark" title="酷玩 Spark" target="_blank">酷玩 Spark</a><ul></ul><a href="http://lqding.blog.51cto.com" title="叮咚的51博客" target="_blank">叮咚的51博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Adam Home.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>