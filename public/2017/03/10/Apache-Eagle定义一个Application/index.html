<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Apache-Eagle定义一个Application | Adam Home</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Apache-Eagle定义一个Application</h1><a id="logo" href="/.">Adam Home</a><p class="description">快意回首，拂心莫停</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于我</i></a><a href="/timeline/"><i class="fa fa-line-chart"> 历史</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Apache-Eagle定义一个Application</h1><div class="post-meta">Mar 10, 2017<span> | </span><span class="category"><a href="/categories/eagle/">eagle</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#配置使用"><span class="toc-number">1.</span> <span class="toc-text">配置使用</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#设计"><span class="toc-number">2.</span> <span class="toc-text">设计</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#alert-engine"><span class="toc-number">2.1.</span> <span class="toc-text">alert engine</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#高层次设计"><span class="toc-number">2.1.1.</span> <span class="toc-text">高层次设计</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#原理"><span class="toc-number">3.</span> <span class="toc-text">原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#配置-Spark-History-Job-Monitor"><span class="toc-number">4.</span> <span class="toc-text">配置 Spark History Job Monitor</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Environment"><span class="toc-number">4.0.1.</span> <span class="toc-text">Environment</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Execution-Mode-选择-Cluster-Mode"><span class="toc-number">4.0.1.1.</span> <span class="toc-text">Execution Mode  选择 Cluster Mode</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Execution-File"><span class="toc-number">4.0.1.2.</span> <span class="toc-text">Execution File</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#General"><span class="toc-number">4.0.2.</span> <span class="toc-text">General</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#resource-manager-url-指的是yarn的那个界面"><span class="toc-number">4.0.2.1.</span> <span class="toc-text">resource manager url  指的是yarn的那个界面</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#hdfs-url-指的是-hdfs的路径"><span class="toc-number">4.0.2.2.</span> <span class="toc-text">hdfs url 指的是 hdfs的路径</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#hdfs-base-path-for-spark-job-data-指的是spark-history-server配置的日志写在hdfs中的路径"><span class="toc-number">4.0.2.3.</span> <span class="toc-text">hdfs base path for spark job data  指的是spark history server配置的日志写在hdfs中的路径</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Advanced"><span class="toc-number">4.0.3.</span> <span class="toc-text">Advanced</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Custom-如果hdfs是Kerberos的话，需要配置Kerberos相关参数"><span class="toc-number">4.0.4.</span> <span class="toc-text">Custom 如果hdfs是Kerberos的话，需要配置Kerberos相关参数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#custom"><span class="toc-number">4.0.5.</span> <span class="toc-text">custom</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#引用"><span class="toc-number">4.0.6.</span> <span class="toc-text">引用</span></a></li></ol></li></ol></li></ol></div></div><div class="post-content"><p>为了监控大数据平台的大量组件与应用，我们决定引入 Apache Eagle()，Apache Eagle是由Ebay贡献并在2017年初成为了顶级项目。。。它的核心就是用一个实时计算平台（Storm），接收数据（kafka等），然后处理，然后存hbase，然后报警。由于缺乏文档，所以最简单的配置使用也是踩了不少坑：<br>当前版本：Eagle 0.5.0 Spark 1.6.2</p>
<h2 id="配置使用"><a href="#配置使用" class="headerlink" title="配置使用"></a>配置使用</h2><p><a href="http://10.142.78.74:8090/#/integration/applicationList" target="_blank" rel="external">http://10.142.78.74:8090/#/integration/applicationList</a></p>
<p><a href="http://10.142.78.100:8080/topology.html?id=SPARK_HISTORY_JOB_APP_TESTENV-38-1489136484" target="_blank" rel="external">http://10.142.78.100:8080/topology.html?id=SPARK_HISTORY_JOB_APP_TESTENV-38-1489136484</a></p>
<p><a href="http://10.142.78.100:60010/master-status" target="_blank" rel="external">http://10.142.78.100:60010/master-status</a></p>
<p><a href="http://www.yiibai.com/hbase/" target="_blank" rel="external">http://www.yiibai.com/hbase/</a></p>
<h2 id="设计"><a href="#设计" class="headerlink" title="设计"></a>设计</h2><h3 id="alert-engine"><a href="#alert-engine" class="headerlink" title="alert engine"></a>alert engine</h3><h4 id="高层次设计"><a href="#高层次设计" class="headerlink" title="高层次设计"></a>高层次设计</h4><p>从高层来看，alert engine 是一个元数据驱动的storm拓扑，它包括了多个模块协同工作：</p>
<ul>
<li>Admin Service - 提供了元数据管理和拓扑管理的API。其中：Metadata store 是 admin service API的具体实现.</li>
<li>Alert Engine Topology on Storm ：通用的Storm 拓扑</li>
<li>Coordinator 协调器： alert engine拓扑的调度程序。它是一个后端调度程序，用于新策略的加载，资源分配，并且暴露了一些内部的API用于管理；</li>
<li>Zookeeper：作为通信和警报引擎之间的通信。</li>
</ul>
<img src="/2017/03/10/Apache-Eagle定义一个Application/eagle_1.png" alt="eagle_1.png" title="">
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>Spark History Job Monitor主要分为两大步骤，在代码中的表现为一个 SparkHistoryJobSpout 和一个 SparkHistoryJobParseBolt：</p>
<p>SparkHistoryJobSpout：从 rm 提供的metric中，解析出 已经完成的spark job：COMPLETE_SPARK_JOB，得到 applicationID，发给下一个Bolt<br>SparkHistoryJobParseBolt：接收到上游发过来的appId后，通过spark的规则，将其</p>
<h2 id="配置-Spark-History-Job-Monitor"><a href="#配置-Spark-History-Job-Monitor" class="headerlink" title="配置 Spark History Job Monitor"></a>配置 Spark History Job Monitor</h2><p>分别点击 <code>Integration</code> -&gt; <code>Sites</code> -&gt; <code>Edit</code> 进入应用配置界面；<br>找到 <code>Spark History Job Monitor</code> 配置，点击右边的 <code>编辑</code>按钮，即可编辑<br>对于 Spark History Job Monitor，由于我们集群是Kerberos的，需要配置以下参数，</p>
<h4 id="Environment"><a href="#Environment" class="headerlink" title="Environment"></a>Environment</h4><h5 id="Execution-Mode-选择-Cluster-Mode"><a href="#Execution-Mode-选择-Cluster-Mode" class="headerlink" title="Execution Mode  选择 Cluster Mode"></a>Execution Mode  选择 Cluster Mode</h5><h5 id="Execution-File"><a href="#Execution-File" class="headerlink" title="Execution File"></a>Execution File</h5><p>默认为：  /usr/local/eagle-0.5.0-SNAPSHOT/lib/eagle-topology-0.5.0-SNAPSHOT-assembly.jar<br>可以不用改</p>
<h4 id="General"><a href="#General" class="headerlink" title="General"></a>General</h4><h5 id="resource-manager-url-指的是yarn的那个界面"><a href="#resource-manager-url-指的是yarn的那个界面" class="headerlink" title="resource manager url  指的是yarn的那个界面"></a>resource manager url  指的是yarn的那个界面</h5><pre><code>http://10.142.78.36:8090/
</code></pre><h5 id="hdfs-url-指的是-hdfs的路径"><a href="#hdfs-url-指的是-hdfs的路径" class="headerlink" title="hdfs url 指的是 hdfs的路径"></a>hdfs url 指的是 hdfs的路径</h5><pre><code>hdfs://10.142.78.98:54310/
</code></pre><h5 id="hdfs-base-path-for-spark-job-data-指的是spark-history-server配置的日志写在hdfs中的路径"><a href="#hdfs-base-path-for-spark-job-data-指的是spark-history-server配置的日志写在hdfs中的路径" class="headerlink" title="hdfs base path for spark job data  指的是spark history server配置的日志写在hdfs中的路径"></a>hdfs base path for spark job data  指的是spark history server配置的日志写在hdfs中的路径</h5><pre><code>hdfs:///user/op/sparkHistoryServe
</code></pre><h4 id="Advanced"><a href="#Advanced" class="headerlink" title="Advanced"></a>Advanced</h4><p>这里主要配的是一些storm以及spark的一些相关参数，可以先不用配</p>
<h4 id="Custom-如果hdfs是Kerberos的话，需要配置Kerberos相关参数"><a href="#Custom-如果hdfs是Kerberos的话，需要配置Kerberos相关参数" class="headerlink" title="Custom 如果hdfs是Kerberos的话，需要配置Kerberos相关参数"></a>Custom 如果hdfs是Kerberos的话，需要配置Kerberos相关参数</h4><p>需要增加如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">dataSourceConfig.hdfs.keytab.file hdfs@HADOOP.CHINATELECOM.CN</div><div class="line">dataSourceConfig.hdfs.kerberos.principal /etc/hadoop/conf/hdfs.keytab</div></pre></td></tr></table></figure>
<h4 id="custom"><a href="#custom" class="headerlink" title="custom"></a>custom</h4><figure class="highlight json"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">    <span class="attr">"workers"</span>: <span class="string">"3"</span>,</div><div class="line">    <span class="attr">"topology.numOfSpoutExecutors"</span>: <span class="string">"1"</span>,</div><div class="line">    <span class="attr">"topology.numOfSpoutTasks"</span>: <span class="string">"1"</span>,</div><div class="line">    <span class="attr">"topology.numOfParseBoltExecutors"</span>: <span class="string">"6"</span>,</div><div class="line">    <span class="attr">"topology.numOfParserBoltTasks"</span>: <span class="string">"6"</span>,</div><div class="line">    <span class="attr">"topology.spoutCrawlInterval"</span>: <span class="string">"60000"</span>,</div><div class="line">    <span class="attr">"topology.requestLimit"</span>: <span class="string">"100"</span>,</div><div class="line">    <span class="attr">"topology.message.timeout.secs"</span>: <span class="string">"600"</span>,</div><div class="line">    <span class="attr">"service.flushLimit"</span>: <span class="string">"500"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.rm.url"</span>: <span class="string">""</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.fs.defaultFS"</span>: <span class="string">"hdfs://xxxxx"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.baseDir"</span>: <span class="string">"/logs/spark-events"</span>,</div><div class="line">    <span class="attr">"spark.jobConf.additional.info"</span>: <span class="string">""</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.executor.memory"</span>: <span class="string">"1g"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.driver.memory"</span>: <span class="string">"1g"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.driver.cores"</span>: <span class="string">"1"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.executor.cores"</span>: <span class="string">"1"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.yarn.am.memory"</span>: <span class="string">"512m"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.yarn.am.cores"</span>: <span class="string">"1"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.yarn.executor.memoryOverhead.factor"</span>: <span class="string">"10"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.yarn.driver.memoryOverhead.factor"</span>: <span class="string">"10"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.yarn.am.memoryOverhead.factor"</span>: <span class="string">"10"</span>,</div><div class="line">    <span class="attr">"spark.defaultVal.spark.yarn.overhead.min"</span>: <span class="string">"384m"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.dfs.namenode.rpc-address.xxxxx.nn1"</span>: <span class="string">"yyyyy"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.dfs.namenode.rpc-address.xxxxx.nn2"</span>: <span class="string">"zzzzz"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.dfs.client.failover.proxy.provider.xxxxx"</span>: <span class="string">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.dfs.nameservices"</span>: <span class="string">"xxxxx"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.dfs.ha.namenodes.xxxxx"</span>: <span class="string">"nn1,nn2"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.hdfs.kerberos.principal"</span>: <span class="string">"aaaaaaa"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.dfs.data.transfer.saslproperties.resolver.class"</span>: <span class="string">"org.apache.hadoop.security.WhitelistBasedResolver"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.hdfs.keytab.file"</span>: <span class="string">"/home/storm/.keytab/b_eagle.keytab"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.dfs.data.transfer.protection"</span>: <span class="string">"authentication,privacy"</span>,</div><div class="line">    <span class="attr">"dataSourceConfig.hdfs.dfs.encrypt.data.transfer.cipher.suites"</span>: <span class="string">"AES/CTR/NoPadding"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight json"><figcaption><span>我们的</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">	<span class="attr">"workers"</span>: <span class="string">"1"</span>,</div><div class="line">	<span class="attr">"topology.numOfSpoutExecutors"</span>: <span class="string">"1"</span>,</div><div class="line">	<span class="attr">"topology.numOfSpoutTasks"</span>: <span class="string">"4"</span>,</div><div class="line">	<span class="attr">"topology.numOfParseBoltExecutors"</span>: <span class="string">"1"</span>,</div><div class="line">	<span class="attr">"topology.numOfParserBoltTasks"</span>: <span class="string">"4"</span>,</div><div class="line">	<span class="attr">"topology.spoutCrawlInterval"</span>: <span class="string">"10000"</span>,</div><div class="line">	<span class="attr">"topology.message.timeout.secs"</span>: <span class="string">"300"</span>,</div><div class="line">	<span class="attr">"service.flushLimit"</span>: <span class="string">"500"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.rm.url"</span>: <span class="string">"http://10.142.78.36:8090/"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.fs.defaultFS"</span>: <span class="string">"hdfs://ns"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.baseDir"</span>: <span class="string">"/user/op/sparkHistoryServer"</span>,</div><div class="line">	<span class="attr">"spark.jobConf.additional.info"</span>: <span class="string">""</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.executor.memory"</span>: <span class="string">"1g"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.driver.memory"</span>: <span class="string">"1g"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.driver.cores"</span>: <span class="string">"1"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.executor.cores"</span>: <span class="string">"1"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.yarn.am.memory"</span>: <span class="string">"512m"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.yarn.am.cores"</span>: <span class="string">"1"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.yarn.executor.memoryOverhead.factor"</span>: <span class="string">"10"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.yarn.driver.memoryOverhead.factor"</span>: <span class="string">"10"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.yarn.am.memoryOverhead.factor"</span>: <span class="string">"10"</span>,</div><div class="line">	<span class="attr">"spark.defaultVal.spark.yarn.overhead.min"</span>: <span class="string">"384m"</span>,</div><div class="line"></div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.namenode.kerberos.principal"</span>: <span class="string">"hdfs/_HOST@HADOOP.CHINATELECOM.CN"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.hadoop.security.authorization"</span>: <span class="string">"true"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.data.transfer.protection"</span>: <span class="string">"authentication,privacy"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.namenode.rpc-address.ns.nn1"</span>: <span class="string">"NM-ITC-NF8460M3-303-011:54310"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.namenode.rpc-address.ns.nn2"</span>: <span class="string">"NM-ITC-NF8460M3-303-012:54310"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.nameservices"</span>: <span class="string">"ns"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.client.failover.proxy.provider.ns"</span>: <span class="string">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.java.security.krb5.kdc"</span>: <span class="string">"test-bdd-073"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.ha.namenodes.ns"</span>: <span class="string">"nn1,nn2"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.encrypt.data.transfer.cipher.suites"</span>: <span class="string">"AES/CTR/NoPadding"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.hdfs.kerberos.principal"</span>: <span class="string">"hdfs@HADOOP.CHINATELECOM.CN"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.dfs.data.transfer.saslproperties.resolver.class"</span>: <span class="string">"org.apache.hadoop.security.WhitelistBasedResolver"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.hadoop.security.authentication"</span>: <span class="string">"kerberos"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.java.security.krb5.conf"</span>: <span class="string">"/etc/krb5.conf"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.java.security.krb5.realm"</span>: <span class="string">"HADOOP.CHINATELECOM.CN"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.hdfs.hdfs.keytab.file"</span>: <span class="string">"/tmp/hdfs.keytab"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<figure class="highlight json"><figcaption><span>,我们的 MR history job</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">&#123;</div><div class="line">	<span class="attr">"workers"</span>: <span class="string">"2"</span>,</div><div class="line">	<span class="attr">"stormConfig.mrHistoryJobSpoutTasks"</span>: <span class="string">"4"</span>,</div><div class="line">	<span class="attr">"stormConfig.jobKafkaSinkTasks"</span>: <span class="string">"1"</span>,</div><div class="line">	<span class="attr">"stormConfig.taskAttemptKafkaSinkTasks"</span>: <span class="string">"1"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.fs.defaultFS"</span>: <span class="string">"hdfs://ns"</span>,</div><div class="line">	<span class="attr">"endpointConfig.basePath"</span>: <span class="string">"/history-yarn/done"</span>,</div><div class="line">	<span class="attr">"endpointConfig.mrHistoryServerUrl"</span>: <span class="string">"http://10.142.78.40:19890"</span>,</div><div class="line">	<span class="attr">"endpointConfig.timeZone"</span>: <span class="string">"Etc/GMT-8"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.MAP_REDUCE_JOB_STREAM.topic"</span>: <span class="string">"map_reduce_job_testenv"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.MAP_REDUCE_TASK_ATTEMPT_STREAM.topic"</span>: <span class="string">"map_reduce_task_attempt_testenv"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.brokerList"</span>: <span class="string">"10.142.78.100:9092"</span>,</div><div class="line">	<span class="attr">"dataSourceConfig.zkConnection"</span>: <span class="string">"10.142.78.98:2181,10.142.78.99:2181,10.142.78.100:2181"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.serializerClass"</span>: <span class="string">"kafka.serializer.StringEncoder"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.keySerializerClass"</span>: <span class="string">"kafka.serializer.StringEncoder"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.producerType"</span>: <span class="string">"async"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.numBatchMessages"</span>: <span class="string">"4096"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.maxQueueBufferMs"</span>: <span class="string">"5000"</span>,</div><div class="line">	<span class="attr">"dataSinkConfig.requestRequiredAcks"</span>: <span class="string">"0"</span>,</div><div class="line">	</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.namenode.kerberos.principal"</span>: <span class="string">"hdfs/_HOST@HADOOP.CHINATELECOM.CN"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.hadoop.security.authorization"</span>: <span class="string">"true"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.data.transfer.protection"</span>: <span class="string">"authentication,privacy"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.namenode.rpc-address.ns.nn1"</span>: <span class="string">"NM-ITC-NF8460M3-303-011:54310"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.namenode.rpc-address.ns.nn2"</span>: <span class="string">"NM-ITC-NF8460M3-303-012:54310"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.nameservices"</span>: <span class="string">"ns"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.client.failover.proxy.provider.ns"</span>: <span class="string">"org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.java.security.krb5.kdc"</span>: <span class="string">"test-bdd-073"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.ha.namenodes.ns"</span>: <span class="string">"nn1,nn2"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.encrypt.data.transfer.cipher.suites"</span>: <span class="string">"AES/CTR/NoPadding"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.hdfs.kerberos.principal"</span>: <span class="string">"hdfs@HADOOP.CHINATELECOM.CN"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.dfs.data.transfer.saslproperties.resolver.class"</span>: <span class="string">"org.apache.hadoop.security.WhitelistBasedResolver"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.hadoop.security.authentication"</span>: <span class="string">"kerberos"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.java.security.krb5.conf"</span>: <span class="string">"/etc/krb5.conf"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.java.security.krb5.realm"</span>: <span class="string">"HADOOP.CHINATELECOM.CN"</span>,</div><div class="line">	<span class="attr">"endpointConfig.hdfs.hdfs.keytab.file"</span>: <span class="string">"/tmp/hdfs.keytab"</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h4 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h4><p><a href="https://eagle.apache.org/" target="_blank" rel="external">https://eagle.apache.org/</a><br><a href="http://www.csdn.net/article/2015-10-29/2826076" target="_blank" rel="external">http://www.csdn.net/article/2015-10-29/2826076</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://flume.cn/2017/03/10/Apache-Eagle定义一个Application/" data-id="cjgd2byfi002tegguwz2u70av" class="article-share-link">分享</a><div class="tags"><a href="/tags/spark/">spark</a><a href="/tags/eagle/">eagle</a></div><div class="post-nav"><a href="/2017/03/13/阿里巴巴Java开发手册学习笔记/" class="pre">阿里巴巴Java开发手册学习笔记（上）</a><a href="/2017/02/28/spark-on-yarn-作业提交源码分析/" class="next">spark on yarn 作业提交源码分析</a></div><div id="uyan_frame"></div><script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2139407"></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/eagle/">eagle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/scala/">scala</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark开发/">spark开发</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spring-cloud/">spring cloud</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/单车岁月/">单车岁月</a><span class="category-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/大数据开发/" style="font-size: 15px;">大数据开发</a> <a href="/tags/scala/" style="font-size: 15px;">scala</a> <a href="/tags/hue/" style="font-size: 15px;">hue</a> <a href="/tags/kerberos/" style="font-size: 15px;">kerberos</a> <a href="/tags/livy/" style="font-size: 15px;">livy</a> <a href="/tags/hbase/" style="font-size: 15px;">hbase</a> <a href="/tags/yarn/" style="font-size: 15px;">yarn</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/flume/" style="font-size: 15px;">flume</a> <a href="/tags/spark-streaming/" style="font-size: 15px;">spark streaming</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/持续更新/" style="font-size: 15px;">持续更新</a> <a href="/tags/spark开发/" style="font-size: 15px;">spark开发</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/散文/" style="font-size: 15px;">散文</a> <a href="/tags/eagle/" style="font-size: 15px;">eagle</a> <a href="/tags/架构/" style="font-size: 15px;">架构</a> <a href="/tags/spring-cloud/" style="font-size: 15px;">spring cloud</a> <a href="/tags/微服务/" style="font-size: 15px;">微服务</a> <a href="/tags/es/" style="font-size: 15px;">es</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/01/08/spark2-2新版本编译打包/">spark2.2新版本编译打包</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/31/使用Ansable安装管理Spark客户端/">使用Ansable安装管理Spark客户端</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/17/spark往ES中写入数据的方法/">spark往ES中写入数据的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/17/spark指定java版本向yarn提交程序/">spark在yarn中运行jdk8</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/29/返回区域实时人数的思路与总结/">返回区域实时人数的思路与总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/28/位置服务开发上线总结/">位置服务开发上线总结————实时数据推送</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/22/spark奇技淫巧总结之flatMap/">spark奇技淫巧总结之强大的flatMap</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/22/OpenAPI微服务接入规范/">OpenAPI微服务接入规范</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/29/OpenApi之我浅薄见解/">OpenApi之我浅薄见解</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/24/阿里巴巴Java开发手册学习笔记2/">阿里巴巴Java开发手册学习笔记（下）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://issues.apache.org/jira/secure/Dashboard.jspa" title="有问题上JIRA" target="_blank">有问题上JIRA</a><ul></ul><a href="https://github.com/lw-lin/CoolplaySpark" title="酷玩 Spark" target="_blank">酷玩 Spark</a><ul></ul><a href="http://lqding.blog.51cto.com" title="叮咚的51博客" target="_blank">叮咚的51博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Adam Home.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>