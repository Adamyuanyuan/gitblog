<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>在Kerberos环境下配置hue通过spark-thrift-server访问SparkSql | Adam Home</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">在Kerberos环境下配置hue通过spark-thrift-server访问SparkSql</h1><a id="logo" href="/.">Adam Home</a><p class="description">快意回首，拂心莫停</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于我</i></a><a href="/timeline/"><i class="fa fa-line-chart"> 历史</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">在Kerberos环境下配置hue通过spark-thrift-server访问SparkSql</h1><div class="post-meta">Sep 5, 2016<span> | </span><span class="category"><a href="/categories/spark/">spark</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="clear"><div id="toc" class="toc-article"><div class="toc-title">文章目录</div><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#背景说明"><span class="toc-number">1.</span> <span class="toc-text">背景说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#40机器hue端配置"><span class="toc-number">2.</span> <span class="toc-text">40机器hue端配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Kerberos服务器端配置"><span class="toc-number">3.</span> <span class="toc-text">Kerberos服务器端配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#76机器上的配置"><span class="toc-number">4.</span> <span class="toc-text">76机器上的配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#从hive-keytab创建spark的keytab"><span class="toc-number">4.1.</span> <span class="toc-text">从hive.keytab创建spark的keytab</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#配置spark需要的hive-site-xml"><span class="toc-number">4.2.</span> <span class="toc-text">配置spark需要的hive-site.xml</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#负载均衡机器的查看"><span class="toc-number">5.</span> <span class="toc-text">负载均衡机器的查看</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#踩坑说明以及解决方案"><span class="toc-number">6.</span> <span class="toc-text">踩坑说明以及解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#缺少配置kerberos认证错误"><span class="toc-number">6.1.</span> <span class="toc-text">缺少配置kerberos认证错误</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#kerberos认证失败"><span class="toc-number">6.2.</span> <span class="toc-text">kerberos认证失败</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hue的配置问题。"><span class="toc-number">6.3.</span> <span class="toc-text">hue的配置问题。</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#metastore的问题"><span class="toc-number">6.4.</span> <span class="toc-text">metastore的问题</span></a></li></ol></li></ol></div></div><div class="post-content"><p>hue-spark-thriftserver-kerberos</p>
<h3 id="背景说明"><a href="#背景说明" class="headerlink" title="背景说明"></a>背景说明</h3><p>Kerberos项目最后要对基于Hue的TODP平台进行安全测试，在搭建配置的过程中踩了一些坑，现在把其中的配置与步骤进行总结，以免以后忘记。</p>
<p>其中用到以下代号：<br>40机器：hue平台所在的机器<br>76机器：spark thrift服务端口10010，hive-thrift-server服务端口10000<br>74机器：spark thrift服务端口10010，hive-thrift-server服务端口10000<br>TEST-BDD-HIVESERVER机器：负载均衡所在的机器，负载均衡机器需要配合开启10000和10010端口</p>
<p>在kerberos认证下, sparksql的thriftserver连接hiveserver2变得相对复杂，主要是因为各种kerberos认证出现各种问题。后来由于hive使用了负载均衡，所以spark-sql也需加入负载均衡，否则不能使用，就是这个负载均衡服务器的加入使得kerberos认证变得更加复杂，使得不明原理的新手在配置kerberos的keytab与principal时各种不匹配。这里是通过Hue可视化界面调用后台的sparksql,然后sparksql通过JDBC连接Hive的hiveServer2服务。</p>
<h3 id="40机器hue端配置"><a href="#40机器hue端配置" class="headerlink" title="40机器hue端配置"></a>40机器hue端配置</h3><p>进入40机器hue所在的目录<br><figure class="highlight bash"><figcaption><span>hue.ini</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ <span class="built_in">cd</span> /usr/lib/hue/ </div><div class="line">$ vim desktop/conf/hue.ini</div></pre></td></tr></table></figure></p>
<p>修改hue的配置文件如下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">1119 [spark]</div><div class="line">...</div><div class="line">1134   <span class="comment"># spark-sql config</span></div><div class="line">1135   spark_sql_server_host=TEST-BDD-HIVESERVER</div><div class="line">1136   <span class="comment">## spark_sql_server_port=10010</span></div></pre></td></tr></table></figure></p>
<p>由于此处使用了负载均衡，所以上述TEST-BDD-HIVESERVER指向的是负载均衡所在的ip，最终会转发给两个spark-thrift-server</p>
<h3 id="Kerberos服务器端配置"><a href="#Kerberos服务器端配置" class="headerlink" title="Kerberos服务器端配置"></a>Kerberos服务器端配置</h3><p>生成类似 hive/test-bdd-hiveserver@HADOOP.CHINATELECOM.CN 的keytab，配置了负载均衡后，使用test-bdd-hiveserver</p>
<h3 id="76机器上的配置"><a href="#76机器上的配置" class="headerlink" title="76机器上的配置"></a>76机器上的配置</h3><p>76机器与74机器配置步骤一样，只是hive-site.xml需要改一处，将下面的 076改成 074即可<br><figure class="highlight bash"><figcaption><span>hive-site.xml</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</div><div class="line">   &lt;value&gt;<span class="built_in">test</span>-bdd-076&lt;/value&gt;</div><div class="line">   &lt;description&gt;TCP port number to listen on, default 10000&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>其它都一样，所以在这里只写076的配置步骤</p>
<h4 id="从hive-keytab创建spark的keytab"><a href="#从hive-keytab创建spark的keytab" class="headerlink" title="从hive.keytab创建spark的keytab"></a>从hive.keytab创建spark的keytab</h4><p>然后在/etc/hive/conf/下创建spark需要的keytab，在这里使用hiveserver的keytab，将已有的hive.keytab_hiveserver 拷贝成 hive.keytab_sparkthrift，然后修改权限如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">-rw------- 1 hive hive     424 8月  23 09:55 hive.keytab_hiveserver</div><div class="line">-rw------- 1 op   bigdata  424 9月   3 12:25 hive.keytab_sparkthrift</div></pre></td></tr></table></figure>
<p>修改好后用如下命令检查：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">$ sudo klist -k hive.keytab_sparkthrift </div><div class="line">Keytab name: FILE:hive.keytab_sparkthrift</div><div class="line">KVNO Principal</div><div class="line">---- --------------------------------------------------------------------------</div><div class="line">   1 hive/<span class="built_in">test</span>-bdd-hiveserver@HADOOP.CHINATELECOM.CN</div><div class="line">   1 hive/<span class="built_in">test</span>-bdd-hiveserver@HADOOP.CHINATELECOM.CN</div><div class="line">   1 hive/<span class="built_in">test</span>-bdd-hiveserver@HADOOP.CHINATELECOM.CN</div><div class="line">   1 hive/<span class="built_in">test</span>-bdd-hiveserver@HADOOP.CHINATELECOM.CN</div><div class="line">   1 hive/<span class="built_in">test</span>-bdd-hiveserver@HADOOP.CHINATELECOM.CN</div></pre></td></tr></table></figure>
<p>如果klist是如上结果，就对了</p>
<h4 id="配置spark需要的hive-site-xml"><a href="#配置spark需要的hive-site-xml" class="headerlink" title="配置spark需要的hive-site.xml"></a>配置spark需要的hive-site.xml</h4><p>由于需要修改hive的一些配置，进入76机器spark所在的目录，将<code>/etc/hive/conf/</code>下的<code>hive-site.xml</code>拷贝到spark的conf下，赋予权限并修改<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ sudo cp /etc/hive/conf/hive-site.xml <span class="variable">$SPARK_HOME</span>/conf/</div><div class="line">$ <span class="built_in">cd</span> <span class="variable">$SPARK_HOME</span></div><div class="line">$ sudo chmod op conf/hive-site.xml</div><div class="line">$ vim conf/hive-site.xml</div></pre></td></tr></table></figure></p>
<p>修改hive-site.xml,增加hive.server2.thrift.bind.host</p>
<figure class="highlight bash"><figcaption><span>hive-site.xml</span></figcaption><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">&lt;!-- ZooKeeper conf--&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt;</div><div class="line">  &lt;value&gt;<span class="literal">false</span>&lt;/value&gt;</div><div class="line">  &lt;description&gt; Impersonate the connected user &lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;hive.server2.thrift.port&lt;/name&gt;</div><div class="line">  &lt;value&gt;10010&lt;/value&gt;</div><div class="line">  &lt;description&gt;TCP port number to listen on, default 10000&lt;/description&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt;</div><div class="line">   &lt;value&gt;<span class="built_in">test</span>-bdd-076&lt;/value&gt;</div><div class="line">   &lt;description&gt;TCP port number to listen on, default 10000&lt;/description&gt;</div><div class="line"> &lt;/property&gt;</div><div class="line"></div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;hive.metastore.execute.setugi&lt;/name&gt;</div><div class="line">  &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">   &lt;name&gt;hive.server2.authentication.kerberos.principal&lt;/name&gt;</div><div class="line">   &lt;value&gt;hive/<span class="built_in">test</span>-bdd-hiveserver@HADOOP.CHINATELECOM.CN&lt;/value&gt;</div><div class="line"> &lt;/property&gt;</div><div class="line">&lt;property&gt;</div><div class="line">  &lt;name&gt;hive.server2.authentication.kerberos.keytab&lt;/name&gt;</div><div class="line">  &lt;value&gt;/etc/hive/conf/hive.keytab_sparkthrift&lt;/value&gt;</div><div class="line">&lt;/property&gt;</div><div class="line"></div><div class="line"><span class="comment">#### 启动Spark-thrift-server</span></div><div class="line">``` bash</div><div class="line">$ <span class="built_in">cd</span> <span class="variable">$SPARK_HOME</span></div><div class="line">$ ./sbin/start-thriftserver.sh</div></pre></td></tr></table></figure>
<p>可以通过如下日志查看是否启动成功：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ vim logs/spark-op-org.apache.spark.sql.hive.thriftserver.HiveThriftServer2-1-TEST-BDD-076.out</div></pre></td></tr></table></figure></p>
<p>启动成功会看到如下日志:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"> 96 16/09/05 13:41:25 INFO AbstractService: Service:HiveServer2 is started.</div><div class="line"> 97 16/09/05 13:41:25 INFO HiveThriftServer2: HiveThriftServer2 started</div><div class="line"> 98 16/09/05 13:41:25 INFO UserGroupInformation: Login successful <span class="keyword">for</span> user hive/<span class="built_in">test</span>-bdd-hiveserver@HADOOP.CHINATELECOM.CN using keytab file /etc/hive/conf/hive.keytab_sparkthrift</div><div class="line"> 99 16/09/05 13:41:25 INFO AbstractDelegationTokenSecretManager: Updating the current master key <span class="keyword">for</span> generating delegation tokens</div><div class="line">100 16/09/05 13:41:25 INFO TokenStoreDelegationTokenSecretManager: New master key with key id=0</div><div class="line">101 16/09/05 13:41:25 INFO TokenStoreDelegationTokenSecretManager: Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)</div><div class="line">102 16/09/05 13:41:25 INFO AbstractDelegationTokenSecretManager: Updating the current master key <span class="keyword">for</span> generating delegation tokens</div><div class="line">103 16/09/05 13:41:25 INFO TokenStoreDelegationTokenSecretManager: New master key with key id=1</div><div class="line">104 16/09/05 13:41:25 INFO ThriftCLIService: Starting ThriftBinaryCLIService on port 10010 with 5...500 worker threads</div></pre></td></tr></table></figure></p>
<h3 id="负载均衡机器的查看"><a href="#负载均衡机器的查看" class="headerlink" title="负载均衡机器的查看"></a>负载均衡机器的查看</h3><p>进入 67.121机器<br>输入 命令 <code>sudo ipvsadm -ln</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">$ sudo ipvsadm -ln</div><div class="line">IP Virtual Server version 1.2.1 (size=4194304)</div><div class="line">Prot LocalAddress:Port Scheduler Flags</div><div class="line">  -&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn</div><div class="line">TCP  10.142.67.123:10000 wlc persistent 7200 synproxy</div><div class="line">  -&gt; 10.142.78.74:10000           FullNat 50     3          0         </div><div class="line">  -&gt; 10.142.78.76:10000           FullNat 50     0          0         </div><div class="line">TCP  10.142.67.123:10010 wlc persistent 7200 synproxy</div><div class="line">  -&gt; 10.142.78.74:10010           FullNat 50     0          0         </div><div class="line">  -&gt; 10.142.78.76:10010           FullNat 50     2          0</div></pre></td></tr></table></figure>
<p>就可以看到负载均衡的情况了：</p>
<h3 id="踩坑说明以及解决方案"><a href="#踩坑说明以及解决方案" class="headerlink" title="踩坑说明以及解决方案"></a>踩坑说明以及解决方案</h3><h4 id="缺少配置kerberos认证错误"><a href="#缺少配置kerberos认证错误" class="headerlink" title="缺少配置kerberos认证错误"></a>缺少配置kerberos认证错误</h4><p>需要在hive-site.xml文件中添加kerberos认证相关配置</p>
<h4 id="kerberos认证失败"><a href="#kerberos认证失败" class="headerlink" title="kerberos认证失败"></a>kerberos认证失败</h4><p>1)  在hive-site.xml中配置好kerberos认证，但是op用户下无法读取hive.keytab的问题，出现unable to login …given keytab/principal 以及Unable to obtain password from user。因为hive.keytab 是hive用户创建的，op用户无法读取，导致看似kerberos已经配置好，<br>但是程序没有读取权限，依旧认为没有配置好，这是会有在日志文件中会有NULLPOINT类似的错误提示，说明是没有读取权限。解决方案是复制hive.keytab到op用户下。<br>2）在hue界面连接spark时可能会出现10010端口不能连接的问题，这是sparkthrift没有启动导致的；<br>3）spark thriftserver明明已经启动，但是hue界面仍旧不能连接，出现TTransportException的错误，原因是kerberos配置没有配置正确，即没有配置kerberos认证的keytab与principal。hive/test-bdd-hiveserver必须与hive.keytab_hiveserver配套使用，同理，test-bdd-074或者 test-bdd-076必须与hive/test-bdd-74或者hive/test-bdd-76配套使用，否则出现认证失败的问题。</p>
<h4 id="hue的配置问题。"><a href="#hue的配置问题。" class="headerlink" title="hue的配置问题。"></a>hue的配置问题。</h4><p>在hue的desktop/conf目录下hue.ini文件中，主要配置spark_sql_server_host，也就是spark thriftserver所在主机，这里可以是负载均衡服务器TEST-BDD-HIVESERVER,spark_sql_server_port 是spark thriftserver的服务端口。<br>需要注意的是，加上kerberos认证后，主机名不能是ip地址的形式，需要FQDN的形式。hive的配置需要注意的是hive_server_host，这里绝对不能是hiveserver2的服务器的地址，一定是负载均衡服务器的地址，不然在hue界面连接HIVE时出现<br>Unable to access databases, Query Server or Metastore may be down.的错误以及GSS initial failed的错误，无法访问hive数据库。</p>
<h4 id="metastore的问题"><a href="#metastore的问题" class="headerlink" title="metastore的问题"></a>metastore的问题</h4><p>连接metastore也需要principal的认证。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">20 &lt;property&gt;</div><div class="line">221   &lt;name&gt;hive.metastore.sasl.enabled&lt;/name&gt;</div><div class="line">222   &lt;value&gt;<span class="literal">true</span>&lt;/value&gt;</div><div class="line">223   &lt;description&gt;If <span class="literal">true</span>, the metastore thrift interface will be secured with SASL. Clients must authenticate with Kerberos.&lt;/description&gt;</div><div class="line">224 &lt;/property&gt;</div><div class="line">225 &lt;property&gt;</div><div class="line">226   &lt;name&gt;hive.metastore.kerberos.principal&lt;/name&gt;</div><div class="line">227   &lt;value&gt;hive/_HOST@HADOOP.CHINATELECOM.CN&lt;/value&gt;</div><div class="line">228   &lt;description&gt;The service principal <span class="keyword">for</span> the metastore thrift server. The special string _HOST will be replaced automatically with the correct host name.&lt;/description&gt;</div><div class="line">229 &lt;/property&gt;</div></pre></td></tr></table></figure></p>
<p>之所以问题多多，主要原因是对kerberos+Hive+lvs整体原理没有搞清楚，以至于在配置过程中出现各种错误。我们搭建的hive集群有74,76两台主机，spark thriftserver也有74,76两台主机，负载均衡服务器在test-bdd-hiveserver上。在配置时，需要将spark-sql-server-host配置成test-bdd-hiveserver,因为对spark而言，74与76上的hiveserver是一个整体，不能配置成单一的主机，不然lvs可能会将服务分到另外一台主机上，造成主机配置失败。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://flume.cn/2016/09/05/在Kerberos环境下配置hue通过spark-thrift-server访问SparkSql/" data-id="cjgd2bybx0006eggu0ns97o8w" class="article-share-link">分享</a><div class="tags"><a href="/tags/spark/">spark</a><a href="/tags/hue/">hue</a><a href="/tags/kerberos/">kerberos</a></div><div class="post-nav"><a href="/2016/09/06/kerberos下spark客户端的配置/" class="pre">kerberos下spark客户端的配置</a><a href="/2016/08/15/spark支持snappy压缩踩坑总结/" class="next">spark支持snappy压缩踩坑总结</a></div><div id="uyan_frame"></div><script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2139407"></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/eagle/">eagle</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/flume/">flume</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/java/">java</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/scala/">scala</a><span class="category-list-count">6</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark/">spark</a><span class="category-list-count">13</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spark开发/">spark开发</a><span class="category-list-count">11</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/spring-cloud/">spring cloud</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/单车岁月/">单车岁月</a><span class="category-list-count">5</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/大数据开发/" style="font-size: 15px;">大数据开发</a> <a href="/tags/scala/" style="font-size: 15px;">scala</a> <a href="/tags/hue/" style="font-size: 15px;">hue</a> <a href="/tags/kerberos/" style="font-size: 15px;">kerberos</a> <a href="/tags/livy/" style="font-size: 15px;">livy</a> <a href="/tags/hbase/" style="font-size: 15px;">hbase</a> <a href="/tags/yarn/" style="font-size: 15px;">yarn</a> <a href="/tags/java/" style="font-size: 15px;">java</a> <a href="/tags/flume/" style="font-size: 15px;">flume</a> <a href="/tags/spark-streaming/" style="font-size: 15px;">spark streaming</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/spark/" style="font-size: 15px;">spark</a> <a href="/tags/redis/" style="font-size: 15px;">redis</a> <a href="/tags/持续更新/" style="font-size: 15px;">持续更新</a> <a href="/tags/spark开发/" style="font-size: 15px;">spark开发</a> <a href="/tags/mysql/" style="font-size: 15px;">mysql</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/散文/" style="font-size: 15px;">散文</a> <a href="/tags/eagle/" style="font-size: 15px;">eagle</a> <a href="/tags/架构/" style="font-size: 15px;">架构</a> <a href="/tags/spring-cloud/" style="font-size: 15px;">spring cloud</a> <a href="/tags/微服务/" style="font-size: 15px;">微服务</a> <a href="/tags/es/" style="font-size: 15px;">es</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/01/08/spark2-2新版本编译打包/">spark2.2新版本编译打包</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/10/31/使用Ansable安装管理Spark客户端/">使用Ansable安装管理Spark客户端</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/17/spark往ES中写入数据的方法/">spark往ES中写入数据的方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/17/spark指定java版本向yarn提交程序/">spark在yarn中运行jdk8</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/29/返回区域实时人数的思路与总结/">返回区域实时人数的思路与总结</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/28/位置服务开发上线总结/">位置服务开发上线总结————实时数据推送</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/06/22/spark奇技淫巧总结之flatMap/">spark奇技淫巧总结之强大的flatMap</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/05/22/OpenAPI微服务接入规范/">OpenAPI微服务接入规范</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/29/OpenApi之我浅薄见解/">OpenApi之我浅薄见解</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/03/24/阿里巴巴Java开发手册学习笔记2/">阿里巴巴Java开发手册学习笔记（下）</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://issues.apache.org/jira/secure/Dashboard.jspa" title="有问题上JIRA" target="_blank">有问题上JIRA</a><ul></ul><a href="https://github.com/lw-lin/CoolplaySpark" title="酷玩 Spark" target="_blank">酷玩 Spark</a><ul></ul><a href="http://lqding.blog.51cto.com" title="叮咚的51博客" target="_blank">叮咚的51博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">Adam Home.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>