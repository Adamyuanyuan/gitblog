---
title: spark2.2新版本编译打包
toc: true
date: 2018-01-08 19:25:39
tags: spark
categories: spark
---

之前已经多次打包过spark了，但是每次重新打包的时候都忘记一些细节，并且spark1.6与2.2打包也有不同，与官网推荐有一些出入，现在就spark2.2.1的打包，总结如下：

由于直接下载预编译好的spark与我们的集群环境不够符合，因此需要下载源码后本地编译
参考：
http://spark.apache.org/docs/latest/building-spark.html

### 前提
安装好了**3.5版本以上的maven** 与java8+ ,spark 2.2.0已经取消了 Java 7的支持，Scala使用 2.11版本
我的环境如下
``` sh
$ scala -version
Scala code runner version 2.11.11 -- Copyright 2002-2017, LAMP/EPFL

Adam@Adam-PC MINGW64 /d/spark
$ java -version
java version "1.8.0_102"
Java(TM) SE Runtime Environment (build 1.8.0_102-b14)
Java HotSpot(TM) 64-Bit Server VM (build 25.102-b14, mixed mode)

Adam@Adam-PC MINGW64 /d/spark
$ mvn -v
Apache Maven 3.5.0 (ff8f5e7444045639af65f6095c62210b5713f426; 2017-04-04T03:39:06+08:00)
```

#### 1. 下载源代码
http://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.2.1/spark-2.2.1.tgz

解压到 `D:\spark\spark-2.2.1`,然后进入这个目录
#### 2. 修改pom.xml文件
加入cloudera的代码仓库，其中可以在profile里面添加相应版本的文件，添加如下内容:
``` xml
<repository>  
  <id>cloudera-repo</id>  
  <name>Cloudera Repository</name>  
  <url>https://repository.cloudera.com/artifactory/cloudera-repos</url>  
  <releases>  
    <enabled>true</enabled> 
  </releases>  
  <snapshots>  
    <enabled>false</enabled>  
  </snapshots>  
</repository>  


<profile>  
  <id>cdh5.4.7</id>  
  <properties>  
    <hadoop.version>2.6.0-cdh5.4.7</hadoop.version>  
    <hbase.version>1.2.4-cdh5.4.7</hbase.version>  
    <zookeeper.version>3.4.5-cdh5.4.7</zookeeper.version>  
  </properties>  
</profile>
```

#### 3. 使用make-distribution编译

设置maven的Memory usage
``` sh
export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m"
```
``` sh
./dev/change-scala-version.sh 2.11
```


#### 4. 编译方法一：使用make-distribution编译
```
./dev/make-distribution.sh --name ctcc --tgz -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0-cdh5.4.7 -Dscala-2.11 -Phive -Phive-thriftserver
```

#### 5. 编译方法二：使用mvn编译
```
./build/mvn  -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0-cdh5.4.7 -Dscala-2.11 -Phive -Phive-thriftserver -DskipTests clean package

// 然后将make-distribution.sh中@BUILD_COMMAND那部分注释掉

./dev/make-distribution.sh --name hadoop-2.6.0-cdh5.4.7 --tgz -Phadoop-2.6  -Dhadoop.version=hadoop-2.6.0-cdh5.4.7 -Phive -Phive-thriftserver -Pyarn

#### 6.编译完成
编译成功后，就会发现多了一个 spark-2.2.1-bin-ctcc.tgz 的文件，解压后就能使用了，我们还要替换一些与hive相关的jar包，比如 hive-exec-1.2.1.spark2.jar 包，替换方法很简单，直接将自己打的包与 /jars 里的包替换一下就好了；

#### 7. 客户端准备
这一部分仅作为记录使用，每个公司使用情况不同，我们是提前准备好客户端，然后下发到每一台机器中，具体步骤如下：
1. 替换掉有bug的jar包： hive-exec-1.2.1.spark2.jar等，这个是我们自己的hive的定制化；
2. 在lib目录下增加一些需要的包，比如hbase相关的包；
3. 在conf目录下配置统一的配置文件，比如 定制化的 hive-site.xml，hbase-site.xml 以及一些通用的配置，比如  spark-defaults.conf  spark-env.sh 等。小版本升级的情况下，可以将conf配置文件配置到其它位置，然后以软链接的形式链接过来。

#### 一些报错的解决
运行的过程中报错：
``` sh
[ERROR] Failed to execute goal on project spark-launcher_2.11: Could not resolve dependencies for project org.apache.spark:spark-launcher_2.11:jar:2.2.0: Could not find artifact org.apache.hadoop:hadoop-client:jar:2.6.0-cdh5.4.7 in central (https://repo1.maven.org/maven2) -> [Help 1]
```
原因是官网是已经无法找到 hadoop-client:jar:2.6.0-cdh5.4.7 这个版本的jar包

从 (https://repository.cloudera.com/content/repositories/releases/org/apache/hadoop/hadoop-client/2.6.0-cdh5.4.7/hadoop-client-2.6.0-cdh5.4.7.jar) 上下载，然后移动懂mvn 本地仓库中
C:\Users\Adam\.m2\repository\org\apache\hadoop\hadoop-client\2.6.0-cdh5.4.7

如果第一次编译出错，在第二次重新编译的时候，会出现一个目录无法删除的情况，导致如下报错：
``` sh
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-clean-plugin:3.0.0:clean (default-clean) on project spark-tags_2.11: Failed to clean project: Failed to delete D:\spark\spark-2.2.0-ctcc\spark-2.2.0\common\tags\target\spark-tags_2.11-2.2.0.jar -> [Help 1]
```
解决方案：跟zinc没有退出有关，在windows当前进程中找到一个Java进程，占用约800M的内存，结束这个进程

再次编译，过段时间继续报错：
``` sh
[ERROR] Failed to execute goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile (scala-compile-first) on project spark-network-yarn_2.11: Execution scala-compile-first of goal net.alchim31.maven:scala-maven-plugin:3.2.2:compile failed. CompileFailed -> [Help 1]
```
解决方案：
删除 C:\Users\Adam\.m2\repository\net\alchim31\maven\scala-maven-plugin\3.2.2 文件，然后重新编译 

会在根目录直接生成 spark-1.6.2-bin-2.6.0-cdh5.4.7.tgz